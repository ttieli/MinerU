#!/usr/bin/env python3
"""
MinerU å…¨åŠŸèƒ½ç‰ˆæ¨¡å‹ä¸‹è½½è„šæœ¬
æ”¯æŒPipelineå’ŒVLMæ¨¡å¼çš„å®Œæ•´æ¨¡å‹ä¸‹è½½
é’ˆå¯¹Apple Siliconä¼˜åŒ–
"""
import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Optional
from huggingface_hub import snapshot_download
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")

class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½ç®¡ç†å™¨"""
    
    def __init__(self, model_source: str = "huggingface"):
        self.model_source = model_source
        self.models_dir = Path("/opt/models")
        self.layoutreader_dir = Path("/opt/layoutreader")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.layoutreader_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.model_configs = self._load_model_configs()
    
    def _load_model_configs(self) -> Dict:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        return {
            "pipeline_models": {
                "repo_id": "opendatalab/PDF-Extract-Kit-1.0",
                "components": {
                    # å¸ƒå±€æ£€æµ‹æ¨¡å‹
                    "layout": {
                        "patterns": ["models/Layout/YOLO/*"],
                        "description": "DocLayout YOLO - æ–‡æ¡£å¸ƒå±€æ£€æµ‹"
                    },
                    # å…¬å¼æ£€æµ‹æ¨¡å‹
                    "formula_detection": {
                        "patterns": ["models/MFD/YOLO/*"],
                        "description": "YOLO v8 MFD - æ•°å­¦å…¬å¼æ£€æµ‹"
                    },
                    # å…¬å¼è¯†åˆ«æ¨¡å‹
                    "formula_recognition": {
                        "patterns": ["models/MFR/unimernet_hf_small_2503/*"],
                        "description": "UniMerNet - æ•°å­¦å…¬å¼è¯†åˆ«"
                    },
                    # OCRæ¨¡å‹
                    "ocr": {
                        "patterns": ["models/OCR/paddleocr_torch/*"],
                        "description": "PaddleOCR PyTorch - æ–‡å­—è¯†åˆ«"
                    },
                    # è¡¨æ ¼è¯†åˆ«æ¨¡å‹
                    "table": {
                        "patterns": ["models/TabRec/SlanetPlus/*"],
                        "description": "SlaNet Plus - è¡¨æ ¼è¯†åˆ«"
                    },
                    # é˜…è¯»é¡ºåºæ¨¡å‹
                    "reading_order": {
                        "patterns": ["models/ReadingOrder/layout_reader/*"],
                        "description": "LayoutReader - é˜…è¯»é¡ºåºæ£€æµ‹"
                    }
                }
            },
            "vlm_models": {
                "repo_id": "opendatalab/MinerU2.0-2505-0.9B",
                "description": "MinerU 2.0 å¤šæ¨¡æ€å¤§æ¨¡å‹",
                "components": {
                    "main_model": {
                        "patterns": ["*.json", "*.safetensors", "*.bin", "tokenizer*"],
                        "description": "ä¸»æ¨¡å‹æ–‡ä»¶å’Œåˆ†è¯å™¨"
                    },
                    "vision_tower": {
                        "patterns": ["vision_tower/*"],
                        "description": "è§†è§‰ç¼–ç å™¨"
                    },
                    "mm_projector": {
                        "patterns": ["mm_projector/*"],
                        "description": "å¤šæ¨¡æ€æŠ•å½±å™¨"
                    }
                }
            },
            "layoutreader": {
                "repo_id": "hantian/layoutreader",
                "description": "LayoutReader - é˜…è¯»é¡ºåºæ£€æµ‹",
                "components": {
                    "model": {
                        "patterns": ["*.json", "*.safetensors", "*.bin"],
                        "description": "LayoutReaderæ¨¡å‹æ–‡ä»¶"
                    }
                }
            }
        }
    
    def download_pipeline_models(self, components: Optional[List[str]] = None) -> bool:
        """ä¸‹è½½Pipelineæ¨¡å¼æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½Pipelineæ¨¡å¼æ¨¡å‹...")
        
        config = self.model_configs["pipeline_models"]
        repo_id = config["repo_id"]
        
        if components is None:
            components = list(config["components"].keys())
        
        try:
            # æ”¶é›†æ‰€æœ‰éœ€è¦ä¸‹è½½çš„æ¨¡å¼
            all_patterns = []
            for component in components:
                if component in config["components"]:
                    patterns = config["components"][component]["patterns"]
                    all_patterns.extend(patterns)
                    logger.info(f"  ğŸ“¦ {config['components'][component]['description']}")
            
            logger.info(f"ä» {repo_id} ä¸‹è½½æ¨¡å‹...")
            
            # ä¸‹è½½æ¨¡å‹
            local_dir = snapshot_download(
                repo_id=repo_id,
                allow_patterns=all_patterns,
                local_dir=str(self.models_dir),
                cache_dir="/tmp/hf_cache",
                resume_download=True,
                local_files_only=False
            )
            
            logger.success(f"âœ… Pipelineæ¨¡å‹ä¸‹è½½å®Œæˆ: {local_dir}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Pipelineæ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_vlm_models(self) -> bool:
        """ä¸‹è½½VLMæ¨¡å¼æ¨¡å‹"""
        logger.info("ğŸ¤– å¼€å§‹ä¸‹è½½VLMå¤šæ¨¡æ€å¤§æ¨¡å‹...")
        
        config = self.model_configs["vlm_models"]
        repo_id = config["repo_id"]
        
        try:
            # VLMæ¨¡å‹ä¸‹è½½åˆ°ä¸“ç”¨ç›®å½•
            vlm_dir = self.models_dir / "vlm"
            vlm_dir.mkdir(exist_ok=True)
            
            logger.info(f"ä» {repo_id} ä¸‹è½½VLMæ¨¡å‹...")
            logger.info(f"  ğŸ§  {config['description']}")
            
            # ä¸‹è½½å®Œæ•´VLMæ¨¡å‹
            local_dir = snapshot_download(
                repo_id=repo_id,
                local_dir=str(vlm_dir),
                cache_dir="/tmp/hf_cache",
                resume_download=True,
                local_files_only=False
            )
            
            logger.success(f"âœ… VLMæ¨¡å‹ä¸‹è½½å®Œæˆ: {local_dir}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ VLMæ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_layoutreader_model(self) -> bool:
        """ä¸‹è½½LayoutReaderæ¨¡å‹"""
        logger.info("ğŸ“– å¼€å§‹ä¸‹è½½LayoutReaderæ¨¡å‹...")
        
        config = self.model_configs["layoutreader"]
        repo_id = config["repo_id"]
        
        try:
            logger.info(f"ä» {repo_id} ä¸‹è½½LayoutReader...")
            logger.info(f"  ğŸ“š {config['description']}")
            
            # æ”¶é›†æ‰€æœ‰æ¨¡å¼
            all_patterns = []
            for component in config["components"].values():
                all_patterns.extend(component["patterns"])
            
            # ä¸‹è½½LayoutReaderæ¨¡å‹
            local_dir = snapshot_download(
                repo_id=repo_id,
                allow_patterns=all_patterns,
                local_dir=str(self.layoutreader_dir),
                cache_dir="/tmp/hf_cache",
                resume_download=True,
                local_files_only=False
            )
            
            logger.success(f"âœ… LayoutReaderæ¨¡å‹ä¸‹è½½å®Œæˆ: {local_dir}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ LayoutReaderæ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_essential_models(self) -> bool:
        """ä¸‹è½½æ ¸å¿ƒå¿…éœ€æ¨¡å‹ï¼ˆç”¨äºDockeræ„å»ºï¼‰"""
        logger.info("âš¡ ä¸‹è½½æ ¸å¿ƒå¿…éœ€æ¨¡å‹...")
        
        # åªä¸‹è½½æœ€å…³é”®çš„ç»„ä»¶
        essential_components = ["layout", "ocr", "formula_detection"]
        
        success = True
        success &= self.download_pipeline_models(essential_components)
        success &= self.download_layoutreader_model()
        
        return success
    
    def download_all_models(self) -> bool:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸŒŸ ä¸‹è½½å®Œæ•´åŠŸèƒ½æ¨¡å‹é›†...")
        
        success = True
        success &= self.download_pipeline_models()
        success &= self.download_vlm_models()
        success &= self.download_layoutreader_model()
        
        return success
    
    def cleanup_cache(self):
        """æ¸…ç†ä¸‹è½½ç¼“å­˜"""
        logger.info("ğŸ§¹ æ¸…ç†ä¸‹è½½ç¼“å­˜...")
        import shutil
        cache_dir = Path("/tmp/hf_cache")
        if cache_dir.exists():
            shutil.rmtree(cache_dir, ignore_errors=True)
            logger.info("âœ… ç¼“å­˜æ¸…ç†å®Œæˆ")
    
    def verify_models(self) -> Dict[str, bool]:
        """éªŒè¯æ¨¡å‹å®Œæ•´æ€§"""
        logger.info("ğŸ” éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")
        
        results = {}
        
        # æ£€æŸ¥Pipelineæ¨¡å‹
        pipeline_paths = {
            "layout": self.models_dir / "models" / "Layout" / "YOLO",
            "mfd": self.models_dir / "models" / "MFD" / "YOLO", 
            "mfr": self.models_dir / "models" / "MFR",
            "ocr": self.models_dir / "models" / "OCR" / "paddleocr_torch",
            "table": self.models_dir / "models" / "TabRec" / "SlanetPlus"
        }
        
        for name, path in pipeline_paths.items():
            exists = path.exists() and any(path.iterdir()) if path.exists() else False
            results[f"pipeline_{name}"] = exists
            status = "âœ…" if exists else "âŒ"
            logger.info(f"  {status} Pipeline {name}: {path}")
        
        # æ£€æŸ¥VLMæ¨¡å‹
        vlm_path = self.models_dir / "vlm"
        vlm_exists = vlm_path.exists() and any(vlm_path.iterdir()) if vlm_path.exists() else False
        results["vlm"] = vlm_exists
        status = "âœ…" if vlm_exists else "âŒ"
        logger.info(f"  {status} VLMæ¨¡å‹: {vlm_path}")
        
        # æ£€æŸ¥LayoutReader
        lr_exists = self.layoutreader_dir.exists() and any(self.layoutreader_dir.iterdir()) if self.layoutreader_dir.exists() else False
        results["layoutreader"] = lr_exists
        status = "âœ…" if lr_exists else "âŒ"
        logger.info(f"  {status} LayoutReader: {self.layoutreader_dir}")
        
        return results
    
    def generate_model_info(self) -> Dict:
        """ç”Ÿæˆæ¨¡å‹ä¿¡æ¯æ‘˜è¦"""
        info = {
            "model_source": self.model_source,
            "models_dir": str(self.models_dir),
            "layoutreader_dir": str(self.layoutreader_dir),
            "verification": self.verify_models(),
            "configs": self.model_configs
        }
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        info_file = self.models_dir / "model_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {info_file}")
        return info

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MinerU å…¨åŠŸèƒ½ç‰ˆæ¨¡å‹ä¸‹è½½å™¨")
    parser.add_argument(
        "--mode", 
        choices=["essential", "pipeline", "vlm", "all"], 
        default="all",
        help="ä¸‹è½½æ¨¡å¼ï¼šessential(æ ¸å¿ƒ), pipeline(ç®¡é“), vlm(å¤šæ¨¡æ€), all(å…¨éƒ¨)"
    )
    parser.add_argument(
        "--source",
        choices=["huggingface", "modelscope"],
        default=os.getenv("MINERU_MODEL_SOURCE", "huggingface"),
        help="æ¨¡å‹æº"
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="åªéªŒè¯æ¨¡å‹å®Œæ•´æ€§ï¼Œä¸ä¸‹è½½"
    )
    parser.add_argument(
        "--cleanup",
        action="store_true", 
        help="ä¸‹è½½åæ¸…ç†ç¼“å­˜"
    )
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ MinerU å…¨åŠŸèƒ½ç‰ˆæ¨¡å‹ä¸‹è½½å™¨")
    logger.info(f"æ¨¡å¼: {args.mode} | æº: {args.source}")
    
    # è®¾ç½®æ¨¡å‹æºç¯å¢ƒå˜é‡
    os.environ["MINERU_MODEL_SOURCE"] = args.source
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ModelDownloader(model_source=args.source)
    
    # å¦‚æœåªæ˜¯éªŒè¯
    if args.verify:
        results = downloader.verify_models()
        all_good = all(results.values())
        logger.info(f"éªŒè¯ç»“æœ: {'âœ… å…¨éƒ¨æ­£å¸¸' if all_good else 'âŒ å­˜åœ¨é—®é¢˜'}")
        return 0 if all_good else 1
    
    # æ‰§è¡Œä¸‹è½½
    success = False
    
    try:
        if args.mode == "essential":
            success = downloader.download_essential_models()
        elif args.mode == "pipeline":
            success = downloader.download_pipeline_models()
        elif args.mode == "vlm":
            success = downloader.download_vlm_models()
        elif args.mode == "all":
            success = downloader.download_all_models()
        
        if success:
            logger.success("ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            
            # ç”Ÿæˆæ¨¡å‹ä¿¡æ¯
            downloader.generate_model_info()
            
            # æ¸…ç†ç¼“å­˜
            if args.cleanup:
                downloader.cleanup_cache()
        else:
            logger.error("ğŸ’¥ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼")
            return 1
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())